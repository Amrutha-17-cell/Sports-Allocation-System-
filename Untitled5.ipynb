{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUy2407dSYJB0Jyq/2Q/1S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amrutha-17-cell/Sports-Allocation-System-/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lLOYl6gDMP2p",
        "outputId": "b3cef32e-c1ff-4703-f35a-90b9515e5aab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-community\n",
            "  Using cached langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Using cached langchain_google_genai-2.1.10-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting langchain-chroma\n",
            "  Downloading langchain_chroma-0.2.6-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-6.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.24)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
            "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting chromadb>=1.0.20 (from langchain-chroma)\n",
            "  Downloading chromadb-1.0.21-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain-chroma) (1.3.0)\n",
            "Collecting pybase64>=1.4.1 (from chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma) (0.35.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain-chroma) (4.15.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain-chroma) (1.36.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain-chroma) (1.36.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain-chroma) (0.22.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain-chroma) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain-chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain-chroma) (1.74.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain-chroma) (0.17.3)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain-chroma) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain-chroma) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain-chroma) (4.25.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb>=1.0.20->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain-chroma) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain-chroma) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain-chroma) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (3.3.1)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.20->langchain-chroma) (8.7.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (1.9.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb>=1.0.20->langchain-chroma) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb>=1.0.20->langchain-chroma) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb>=1.0.20->langchain-chroma) (0.34.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb>=1.0.20->langchain-chroma) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb>=1.0.20->langchain-chroma) (1.5.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.20->langchain-chroma) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.20->langchain-chroma) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.20->langchain-chroma) (1.1.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.20->langchain-chroma) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.20->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma) (1.3.0)\n",
            "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.10-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_chroma-0.2.6-py3-none-any.whl (12 kB)\n",
            "Downloading pypdf-6.0.0-py3-none-any.whl (310 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.0.21-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=7e68975e6a67c3d2d27c235914fd570511de7948af0186427fe68db801e242e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, filetype, durationpy, uvloop, requests, pypdf, pybase64, opentelemetry-proto, mypy-extensions, mmh3, marshmallow, humanfriendly, httptools, bcrypt, backoff, watchfiles, typing-inspect, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, kubernetes, dataclasses-json, opentelemetry-sdk, langchain-core, opentelemetry-exporter-otlp-proto-grpc, google-ai-generativelanguage, langchain-google-genai, chromadb, langchain-community, langchain-chroma\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.36.0\n",
            "    Uninstalling opentelemetry-api-1.36.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.36.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.57b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.57b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.57b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.36.0\n",
            "    Uninstalling opentelemetry-sdk-1.36.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.36.0\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.75\n",
            "    Uninstalling langchain-core-0.3.75:\n",
            "      Successfully uninstalled langchain-core-0.3.75\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.21 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 filetype-1.2.0 google-ai-generativelanguage-0.6.18 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 langchain-chroma-0.2.6 langchain-community-0.3.29 langchain-core-0.3.76 langchain-google-genai-2.1.10 marshmallow-3.26.1 mmh3-5.2.0 mypy-extensions-1.1.0 onnxruntime-1.22.1 opentelemetry-api-1.37.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 posthog-5.4.0 pybase64-1.4.2 pypdf-6.0.0 pypika-0.48.9 requests-2.32.5 typing-inspect-0.9.0 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "428f164717c548a99a92ec14f1c027f3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install langchain langchain-community langchain-google-genai langchain-chroma pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import os"
      ],
      "metadata": {
        "id": "-8BENXzFNLAW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"file1.pdf\")\n",
        "docs = loader.load()\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJb3sPNZNTMW",
        "outputId": "f989541c-655e-4ce0-b99a-f7e2af9ba5f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-20T19:50:46+05:30', 'author': 'user', 'moddate': '2025-02-20T19:50:46+05:30', 'source': 'file1.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1'}, page_content='Kth Largest Element in an Array \\nimport heapq \\n \\ndef findKthLargest(nums, k): \\n    # Create a min-heap with the first k elements of the array \\n    min_heap = nums[:k] \\n    heapq.heapify(min_heap) \\n \\n    # Iterate over the rest of the array \\n    for num in nums[k:]: \\n        if num > min_heap[0]: \\n            # If the current number is larger than the smallest in the heap, replace it \\n            heapq.heappushpop(min_heap, num) \\n \\n    # The root of the heap will be the kth largest element \\n    return min_heap[0] \\n \\n# Input reading and function call \\nn = int(input())  # Number of elements in the array \\nnums = [int(input()) for _ in range(n)]  # Array elements \\nk = int(input())  # The kth largest number to find \\n \\n# Output the result \\nprint(findKthLargest(nums, k))'),\n",
              " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-20T19:50:46+05:30', 'author': 'user', 'moddate': '2025-02-20T19:50:46+05:30', 'source': 'file1.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2'}, page_content='FizzBuzz \\n \\ndef fizzBuzz(n): \\n    result = [] \\n    for i in range(1, n + 1): \\n        if i % 3 == 0 and i % 5 == 0: \\n            result.append(\"FizzBuzz\") \\n        elif i % 3 == 0: \\n            result.append(\"Fizz\") \\n        elif i % 5 == 0: \\n            result.append(\"Buzz\") \\n        else: \\n            result.append(str(i)) \\n    return result \\n \\nif __name__ == \"__main__\": \\n    n = int(input()) \\n    output = fizzBuzz(n) \\n    print(output)'),\n",
              " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-20T19:50:46+05:30', 'author': 'user', 'moddate': '2025-02-20T19:50:46+05:30', 'source': 'file1.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3'}, page_content='Sort Array in Wave Form \\n \\ndef wave_sort(arr): \\n    arr.sort() \\n    for i in range(0, len(arr) - 1, 2): \\n        arr[i], arr[i + 1] = arr[i + 1], arr[i] \\n    print(*arr,sep=\"\\\\n\") \\n \\nn = int(input()) \\narr = [int(input()) for _ in range(n)] \\nwave_sort(arr) \\n \\nIntersection of Two Arrays \\ndef intersection(nums1, nums2): \\n    return list(set(nums1) & set(nums2)) \\n \\nif __name__ == \"__main__\": \\n    n = int(input()) \\n    nums1 = [int(input()) for _ in range(n)] \\n     \\n    m = int(input()) \\n    nums2 = [int(input()) for _ in range(m)] \\n     \\n    result = intersection(nums1, nums2) \\n    print(sorted(result))  # Sorting to maintain consistent output format'),\n",
              " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-20T19:50:46+05:30', 'author': 'user', 'moddate': '2025-02-20T19:50:46+05:30', 'source': 'file1.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4'}, page_content='Convert Integer to Excel Column Title \\n \\ndef convertToTitle(columnNumber): \\n    result = [] \\n    while columnNumber > 0: \\n        columnNumber -= 1 \\n        result.append(chr(columnNumber % 26 + ord(\\'A\\'))) \\n        columnNumber //= 26 \\n    return \\'\\'.join(result[::-1]) \\n \\nif __name__ == \"__main__\": \\n    columnNumber = int(input()) \\n    print(convertToTitle(columnNumber)) \\n \\n \\nFind the Middle of a Linked List \\nclass ListNode: \\n    def __init__(self, val=0, next=None): \\n        self.val = val \\n        self.next = next \\n \\ndef findMiddle(head): \\n    slow = fast = head \\n    while fast and fast.next:'),\n",
              " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-20T19:50:46+05:30', 'author': 'user', 'moddate': '2025-02-20T19:50:46+05:30', 'source': 'file1.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5'}, page_content='slow = slow.next \\n        fast = fast.next.next \\n    return slow.val \\n \\ndef createLinkedList(values): \\n    if not values: \\n        return None \\n    head = ListNode(values[0]) \\n    current = head \\n    for val in values[1:]: \\n        current.next = ListNode(val) \\n        current = current.next \\n    return head \\n \\nif __name__ == \"__main__\": \\n    values = list(map(int, input().split())) \\n    head = createLinkedList(values) \\n    print(findMiddle(head)) \\n \\nFind the First Unique Character in a String \\ndef firstUniqChar(s): \\n     \\n    char_count = {} \\n     \\n     \\n    for char in s: \\n        if char in char_count: \\n            char_count[char] += 1'),\n",
              " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-20T19:50:46+05:30', 'author': 'user', 'moddate': '2025-02-20T19:50:46+05:30', 'source': 'file1.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6'}, page_content='else: \\n            char_count[char] = 1 \\n     \\n     \\n    for i in range(len(s)): \\n        if char_count[s[i]] == 1: \\n            return i \\n     \\n     \\n    return -1 \\ninput_string = input().strip()   \\nprint(firstUniqChar(input_string))   \\n \\n \\n scrambled string \\n \\ndef isScramble(s1, s2): \\n    \\n    memo = {} \\n \\n     \\n    def helper(s1, s2): \\n         \\n        if (s1, s2) in memo: \\n            return memo[(s1, s2)] \\n \\n        \\n        if s1 == s2: \\n            memo[(s1, s2)] = True \\n            return True \\n         \\n         \\n        if sorted(s1) != sorted(s2): \\n            memo[(s1, s2)] = False \\n            return False \\n \\n         \\n        n = len(s1) \\n        for i in range(1, n):'),\n",
              " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-20T19:50:46+05:30', 'author': 'user', 'moddate': '2025-02-20T19:50:46+05:30', 'source': 'file1.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='if helper(s1[:i], s2[:i]) and helper(s1[i:], s2[i:]): \\n                memo[(s1, s2)] = True \\n                return True \\n             \\n             \\n            if helper(s1[:i], s2[-i:]) and helper(s1[i:], s2[:-i]): \\n                memo[(s1, s2)] = True \\n                return True \\n \\n         \\n        memo[(s1, s2)] = False \\n        return False \\n \\n    return helper(s1, s2) \\n \\ns1 = input().strip()   \\ns2 = input().strip()   \\n \\n \\nprint(isScramble(s1, s2)) \\n \\nWiggle Sort \\n#include <stdio.h> \\n \\n \\nvoid wiggleSort(int nums[], int n) { \\n    for (int i = 1; i < n; i++) { \\n        if ((i % 2 == 1 && nums[i] < nums[i - 1]) ||   \\n            (i % 2 == 0 && nums[i] > nums[i - 1])) {   \\n            int temp = nums[i]; \\n            nums[i] = nums[i - 1]; \\n            nums[i - 1] = temp; \\n        } \\n    } \\n}'),\n",
              " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-20T19:50:46+05:30', 'author': 'user', 'moddate': '2025-02-20T19:50:46+05:30', 'source': 'file1.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='int main() { \\n    int n; \\n    scanf(\"%d\", &n);   \\n \\n    int nums[n]; \\n    for (int i = 0; i < n; i++) { \\n        scanf(\"%d\", &nums[i]);   \\n    } \\n \\n    wiggleSort(nums, n);   \\n \\n     \\n    for (int i = 0; i < n; i++) { \\n        printf(\"%d \", nums[i]); \\n    } \\n    printf(\"\\\\n\"); \\n \\n    return 0; \\n} \\n \\nCount Inversions in an Array \\n \\ndef merge_count_split_inv(arr, temp_arr, left, right): \\n    if left == right: \\n        return 0 \\n     \\n    mid = (left + right) // 2 \\n    inv_count = merge_count_split_inv(arr, temp_arr, left, mid) \\n    inv_count += merge_count_split_inv(arr, temp_arr, mid + 1, right) \\n    inv_count += merge_and_count(arr, temp_arr, left, mid, right) \\n     \\n    return inv_count'),\n",
              " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-20T19:50:46+05:30', 'author': 'user', 'moddate': '2025-02-20T19:50:46+05:30', 'source': 'file1.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9'}, page_content='def merge_and_count(arr, temp_arr, left, mid, right): \\n    i = left    # Starting index for left subarray \\n    j = mid + 1 # Starting index for right subarray \\n    k = left    # Starting index to be sorted \\n    inv_count = 0 \\n     \\n    while i <= mid and j <= right: \\n        if arr[i] <= arr[j]: \\n            temp_arr[k] = arr[i] \\n            i += 1 \\n        else: \\n            temp_arr[k] = arr[j] \\n            inv_count += (mid - i + 1) \\n            j += 1 \\n        k += 1 \\n     \\n    while i <= mid: \\n        temp_arr[k] = arr[i] \\n        i += 1 \\n        k += 1 \\n     \\n    while j <= right: \\n        temp_arr[k] = arr[j] \\n        j += 1'),\n",
              " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-20T19:50:46+05:30', 'author': 'user', 'moddate': '2025-02-20T19:50:46+05:30', 'source': 'file1.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10'}, page_content='k += 1 \\n     \\n    for i in range(left, right + 1): \\n        arr[i] = temp_arr[i] \\n     \\n    return inv_count \\n \\ndef count_inversions(arr): \\n    n = len(arr) \\n    temp_arr = [0] * n \\n    return merge_count_split_inv(arr, temp_arr, 0, n - 1) \\n \\n# Input reading \\nn = int(input())  # Read the number of elements \\narr = [int(input()) for _ in range(n)]  # Read the array elements \\n \\n# Output the number of inversions \\nprint(count_inversions(arr)) \\n \\nTwo Sum – Hash map \\n#include <stdio.h> \\n#include <stdlib.h> \\n \\n// Structure for hash table entries \\ntypedef struct {'),\n",
              " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-20T19:50:46+05:30', 'author': 'user', 'moddate': '2025-02-20T19:50:46+05:30', 'source': 'file1.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11'}, page_content='int value; \\n    int index; \\n} HashEntry; \\n \\n// Simple hash function \\nint hashFunction(int key, int size) { \\n    return abs(key) % size; \\n} \\n \\n// Function to find two sum using hash map \\nvoid twoSum(int nums[], int n, int target) { \\n    int hashSize = n * 2;  // Increase size to reduce collisions \\n    HashEntry* hashTable = (HashEntry*)calloc(hashSize, sizeof(HashEntry)); \\n     \\n    for (int i = 0; i < n; i++) { \\n        int complement = target - nums[i]; \\n        int hashIndex = hashFunction(complement, hashSize); \\n         \\n        if (hashTable[hashIndex].value == complement) { \\n            printf(\"%d %d\\\\n\", hashTable[hashIndex].index, i); \\n            free(hashTable); \\n            return; \\n        } \\n \\n        hashIndex = hashFunction(nums[i], hashSize);'),\n",
              " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-20T19:50:46+05:30', 'author': 'user', 'moddate': '2025-02-20T19:50:46+05:30', 'source': 'file1.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='hashTable[hashIndex].value = nums[i]; \\n        hashTable[hashIndex].index = i; \\n    } \\n \\n    free(hashTable); \\n    printf(\"-1 -1\\\\n\");  // No valid pair found (shouldn\\'t happen based on constraints) \\n} \\n \\nint main() { \\n    int n; \\n    scanf(\"%d\", &n); \\n     \\n    int* nums = (int*)malloc(n * sizeof(int)); \\n    for (int i = 0; i < n; i++) { \\n        scanf(\"%d\", &nums[i]); \\n    } \\n \\n    int target; \\n    scanf(\"%d\", &target); \\n \\n    twoSum(nums, n, target); \\n \\n    free(nums); \\n    return 0; \\n}'),\n",
              " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-20T19:50:46+05:30', 'author': 'user', 'moddate': '2025-02-20T19:50:46+05:30', 'source': 'file1.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='Two Sum – Hash map \\nimport java.util.HashMap; \\nimport java.util.Scanner; \\n \\npublic class TwoSum { \\n    \\n     \\n    public static int[] twoSum(int[] nums, int target) { \\n         \\n        HashMap<Integer, Integer> map = new HashMap<>(); \\n         \\n         \\n        for (int i = 0; i < nums.length; i++) { \\n            int complement = target - nums[i]; \\n             \\n             \\n            if (map.containsKey(complement)) { \\n                return new int[] { map.get(complement), i }; \\n            } \\n             \\n             \\n            map.put(nums[i], i); \\n        }'),\n",
              " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-20T19:50:46+05:30', 'author': 'user', 'moddate': '2025-02-20T19:50:46+05:30', 'source': 'file1.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content='return new int[] {}; \\n    } \\n \\n    public static void main(String[] args) { \\n         \\n        Scanner scanner = new Scanner(System.in); \\n         \\n         \\n        int n = scanner.nextInt(); \\n         \\n         \\n        int[] nums = new int[n]; \\n         \\n        for (int i = 0; i < n; i++) { \\n            nums[i] = scanner.nextInt(); \\n        } \\n         \\n         \\n        int target = scanner.nextInt(); \\n         \\n         \\n        int[] result = twoSum(nums, target);'),\n",
              " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-20T19:50:46+05:30', 'author': 'user', 'moddate': '2025-02-20T19:50:46+05:30', 'source': 'file1.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15'}, page_content='if (result.length > 0) { \\n            System.out.println(result[0] + \" \" + result[1]); \\n        } else { \\n            System.out.println(\"No solution\"); \\n        } \\n         \\n        scanner.close(); \\n    } \\n} \\nDelete a Node in a Doubly Linked List \\nclass ListNode: \\n    def __init__(self, val=0, prev=None, next=None): \\n        self.val = val \\n        self.prev = prev \\n        self.next = next \\n \\ndef deleteNode(head, node_val): \\n    if not head: \\n        return None  # Return if the list is empty \\n \\n    current = head \\n    while current: \\n        if current.val == node_val: \\n            # Case 1: Deleting the head node \\n            if current == head:'),\n",
              " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-20T19:50:46+05:30', 'author': 'user', 'moddate': '2025-02-20T19:50:46+05:30', 'source': 'file1.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16'}, page_content='head = head.next \\n                if head: \\n                    head.prev = None \\n                return head \\n             \\n            # Case 2: Deleting a middle or last node \\n            if current.next: \\n                current.next.prev = current.prev \\n            if current.prev: \\n                current.prev.next = current.next \\n            return head  # Return the updated head \\n         \\n        current = current.next \\n \\n    return head  # Return the head if node_val was not found \\n \\ndef printList(head): \\n    result = [] \\n    current = head \\n    while current: \\n        result.append(current.val) \\n        current = current.next \\n    print(result) \\n \\ndef createDoublyLinkedList(values):'),\n",
              " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-20T19:50:46+05:30', 'author': 'user', 'moddate': '2025-02-20T19:50:46+05:30', 'source': 'file1.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17'}, page_content='if not values: \\n        return None \\n    head = ListNode(values[0]) \\n    current = head \\n    for val in values[1:]: \\n        new_node = ListNode(val) \\n        current.next = new_node \\n        new_node.prev = current \\n        current = new_node \\n    return head \\n \\nif __name__ == \"__main__\": \\n    values = list(map(int, input().split())) \\n    node_val = int(input()) \\n    head = createDoublyLinkedList(values) \\n    modified_head = deleteNode(head, node_val) \\n    printList(modified_head)')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        ")\n",
        "chunks = splitter.split_documents(docs)\n",
        "print(len(chunks))\n",
        "print(chunks[0].page_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsoe1pdkNYMm",
        "outputId": "76e1de65-347d-4561-db20-1e1d14e47d32"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n",
            "Kth Largest Element in an Array \n",
            "import heapq \n",
            " \n",
            "def findKthLargest(nums, k): \n",
            "    # Create a min-heap with the first k elements of the array \n",
            "    min_heap = nums[:k] \n",
            "    heapq.heapify(min_heap) \n",
            " \n",
            "    # Iterate over the rest of the array \n",
            "    for num in nums[k:]: \n",
            "        if num > min_heap[0]: \n",
            "            # If the current number is larger than the smallest in the heap, replace it \n",
            "            heapq.heappushpop(min_heap, num) \n",
            " \n",
            "    # The root of the heap will be the kth largest element \n",
            "    return min_heap[0] \n",
            " \n",
            "# Input reading and function call \n",
            "n = int(input())  # Number of elements in the array \n",
            "nums = [int(input()) for _ in range(n)]  # Array elements \n",
            "k = int(input())  # The kth largest number to find \n",
            " \n",
            "# Output the result \n",
            "print(findKthLargest(nums, k))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "# Set the Google API Key as an environment variable\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\", google_api_key=os.environ[\"GOOGLE_API_KEY\"])"
      ],
      "metadata": {
        "id": "nbdUr82VOqTm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = Chroma.from_documents(documents=chunks, embedding=embeddings)\n"
      ],
      "metadata": {
        "id": "ynQSdIdcOyDv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# similarity search\n",
        "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
      ],
      "metadata": {
        "id": "Wa0DRx8eO4Re"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0.9,\n",
        "    max_output_tokens=500\n",
        ")"
      ],
      "metadata": {
        "id": "YGwB56WJO6XW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "      You are a helpful assistant.\n",
        "      Answer from the provided transcript context..\n",
        "\n",
        "      {context}\n",
        "      Question: {question}\n",
        "    \"\"\",\n",
        "    input_variables=['context', 'question']\n",
        ")"
      ],
      "metadata": {
        "id": "rQUU-yzmO9Bm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = 'what are the allowences given to the employee'\n",
        "retrieved_docs = retriever.invoke(question)\n",
        "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])"
      ],
      "metadata": {
        "id": "hXLwxIToO_0W"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt = prompt.invoke({\n",
        "    \"context\": context,\n",
        "    \"question\": question\n",
        "})\n",
        "final_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJKYs5ChPC8-",
        "outputId": "c7cdbced-c758-4eee-87e2-8877b0927154"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringPromptValue(text='\\n      You are a helpful assistant.\\n      Answer from the provided transcript context..\\n\\n      Convert Integer to Excel Column Title \\n \\ndef convertToTitle(columnNumber): \\n    result = [] \\n    while columnNumber > 0: \\n        columnNumber -= 1 \\n        result.append(chr(columnNumber % 26 + ord(\\'A\\'))) \\n        columnNumber //= 26 \\n    return \\'\\'.join(result[::-1]) \\n \\nif __name__ == \"__main__\": \\n    columnNumber = int(input()) \\n    print(convertToTitle(columnNumber)) \\n \\n \\nFind the Middle of a Linked List \\nclass ListNode: \\n    def __init__(self, val=0, next=None): \\n        self.val = val \\n        self.next = next \\n \\ndef findMiddle(head): \\n    slow = fast = head \\n    while fast and fast.next:\\n\\nelse: \\n            char_count[char] = 1 \\n     \\n     \\n    for i in range(len(s)): \\n        if char_count[s[i]] == 1: \\n            return i \\n     \\n     \\n    return -1 \\ninput_string = input().strip()   \\nprint(firstUniqChar(input_string))   \\n \\n \\n scrambled string \\n \\ndef isScramble(s1, s2): \\n    \\n    memo = {} \\n \\n     \\n    def helper(s1, s2): \\n         \\n        if (s1, s2) in memo: \\n            return memo[(s1, s2)] \\n \\n        \\n        if s1 == s2: \\n            memo[(s1, s2)] = True \\n            return True \\n         \\n         \\n        if sorted(s1) != sorted(s2): \\n            memo[(s1, s2)] = False \\n            return False \\n \\n         \\n        n = len(s1) \\n        for i in range(1, n):\\n\\nSort Array in Wave Form \\n \\ndef wave_sort(arr): \\n    arr.sort() \\n    for i in range(0, len(arr) - 1, 2): \\n        arr[i], arr[i + 1] = arr[i + 1], arr[i] \\n    print(*arr,sep=\"\\\\n\") \\n \\nn = int(input()) \\narr = [int(input()) for _ in range(n)] \\nwave_sort(arr) \\n \\nIntersection of Two Arrays \\ndef intersection(nums1, nums2): \\n    return list(set(nums1) & set(nums2)) \\n \\nif __name__ == \"__main__\": \\n    n = int(input()) \\n    nums1 = [int(input()) for _ in range(n)] \\n     \\n    m = int(input()) \\n    nums2 = [int(input()) for _ in range(m)] \\n     \\n    result = intersection(nums1, nums2) \\n    print(sorted(result))  # Sorting to maintain consistent output format\\n\\nk += 1 \\n     \\n    for i in range(left, right + 1): \\n        arr[i] = temp_arr[i] \\n     \\n    return inv_count \\n \\ndef count_inversions(arr): \\n    n = len(arr) \\n    temp_arr = [0] * n \\n    return merge_count_split_inv(arr, temp_arr, 0, n - 1) \\n \\n# Input reading \\nn = int(input())  # Read the number of elements \\narr = [int(input()) for _ in range(n)]  # Read the array elements \\n \\n# Output the number of inversions \\nprint(count_inversions(arr)) \\n \\nTwo Sum – Hash map \\n#include <stdio.h> \\n#include <stdlib.h> \\n \\n// Structure for hash table entries \\ntypedef struct {\\n\\nif (result.length > 0) { \\n            System.out.println(result[0] + \" \" + result[1]); \\n        } else { \\n            System.out.println(\"No solution\"); \\n        } \\n         \\n        scanner.close(); \\n    } \\n} \\nDelete a Node in a Doubly Linked List \\nclass ListNode: \\n    def __init__(self, val=0, prev=None, next=None): \\n        self.val = val \\n        self.prev = prev \\n        self.next = next \\n \\ndef deleteNode(head, node_val): \\n    if not head: \\n        return None  # Return if the list is empty \\n \\n    current = head \\n    while current: \\n        if current.val == node_val: \\n            # Case 1: Deleting the head node \\n            if current == head:\\n      Question: what are the allowences given to the employee\\n    ')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = StrOutputParser()\n",
        "\n",
        "# Generate the answer\n",
        "response = chat_model.invoke(final_prompt)\n",
        "\n",
        "parser.invoke(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "FBCsECzyPGNe",
        "outputId": "de3afa70-fb15-4f89-fcaa-4becd9cf7a57"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The provided transcript context contains various programming code snippets and problem descriptions (like \"Convert Integer to Excel Column Title\", \"Find the Middle of a Linked List\", \"Scrambled string\", \"Sort Array in Wave Form\", \"Intersection of Two Arrays\", \"Two Sum – Hash map\", \"Delete a Node in a Doubly Linked List\", and an inversion count algorithm).\\n\\nThere is **no information** regarding allowances given to'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}